# μμ„± λ©΄μ ‘ μ‹μ¤ν… μ•„ν‚¤ν…μ²

## κ°μ”

STT β†’ LLM β†’ TTS νμ΄ν”„λΌμΈ κΈ°λ° μμ„± λ©΄μ ‘ μ‹μ¤ν…

**μ¤‘μ”**: π¨ **A6000 μ„λ²„ λ§μ΄κ·Έλ μ΄μ… λ€μƒ**
- ν„μ¬: λ΅μ»¬ Whisper (openai-whisper, CPU) + Melo TTS λ΅μ»¬ μ„λ²„
- ν–¥ν›„: A6000 μ„λ²„μ λ΅μ»¬ λ¨λΈλ΅ μ™„μ „ λ€μ²΄

---

## μ‹μ¤ν… κµ¬μ„±λ„

```
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚  Frontend   β”‚
β”‚  (React)    β”‚
β””β”€β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”€β”€β”€β”
      β”‚ WebRTC Audio Recording
      β–Ό
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚         FastAPI Backend                 β”‚
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¤
β”‚  POST /api/session/start                β”‚
β”‚  POST /api/answer/complete              β”‚
β””β”€β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
      β”‚
      β–Ό
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚    InterviewOrchestrator Service        β”‚
β””β”€β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
      β”‚
      β”β”€β”€β–Ί π”΄ WhisperClient (STT)
      β”‚    β””β”€β–Ί ν„μ¬: WhisperLocalClient (openai-whisper @ CPU)
      β”‚    β””β”€β–Ί ν–¥ν›„: A6000 Whisper Large-v3
      β”‚
      β”β”€β”€β–Ί π΅ GeminiClient (LLM)
      β”‚    β””β”€β–Ί ν„μ¬: Google Gemini API
      β”‚    β””β”€β–Ί ν–¥ν›„: A6000 LLaMA/Gemma
      β”‚
      β””β”€β”€β–Ί π”΄ MeloTTSClient (TTS)
           β””β”€β–Ί ν„μ¬: λ΅μ»¬ CPU Melo TTS
           β””β”€β–Ί ν–¥ν›„: A6000 GPU Melo TTS / VITS
```

---

## π¨ A6000 μ„λ²„ λ§μ΄κ·Έλ μ΄μ… κ³„ν

### Phase 1: MVP (ν„μ¬)
- **STT**: openai-whisper λ΅μ»¬ λ¨λΈ (CPU, λ¬΄λ£)
- **LLM**: Google Gemini API (λ¬΄λ£ ν‹°μ–΄)
- **TTS**: Melo TTS (λ΅μ»¬ CPU)

### Phase 2: A6000 ν†µν•© (λ©ν‘)
- **STT**: Whisper Large-v3 @ A6000 GPU
  - μ—”λ“ν¬μΈνΈ: `http://a6000-server:8002/stt`
  - νμΌ μ—…λ΅λ“ β†’ JSON μ‘λ‹µ
- **LLM**: LLaMA 3.1 or Gemma 2 @ A6000 GPU
  - μ—”λ“ν¬μΈνΈ: `http://a6000-server:8003/generate`
  - ν”„λ΅¬ν”„νΈ μ „μ†΅ β†’ ν…μ¤νΈ μ‘λ‹µ
- **TTS**: Melo TTS GPU or VITS @ A6000 GPU
  - μ—”λ“ν¬μΈνΈ: `http://a6000-server:8004/tts`
  - ν…μ¤νΈ β†’ μμ„± νμΌ URL

### λ§μ΄κ·Έλ μ΄μ… μ²΄ν¬λ¦¬μ¤νΈ

- [ ] A6000 μ„λ²„μ— Whisper Large-v3 FastAPI μ„λ²„ κµ¬μ¶•
- [ ] A6000 μ„λ²„μ— LLM μ¶”λ΅  μ„λ²„ κµ¬μ¶• (vLLM or TGI)
- [ ] A6000 μ„λ²„μ— TTS μ„λ²„ κµ¬μ¶•
- [ ] ν™κ²½ λ³€μλ΅ μ—”λ“ν¬μΈνΈ μ „ν™ (`USE_A6000_MODELS=true`)
- [ ] Client μΈν„°νμ΄μ¤λ” κ·Έλ€λ΅, κµ¬ν„μ²΄λ§ κµμ²΄
- [ ] μ„±λ¥ ν…μ¤νΈ (latency, throughput)

---

## νμΌ κµ¬μ΅°

```
backend/
β”β”€β”€ VOICE_INTERVIEW_ARCHITECTURE.md  # μ΄ λ¬Έμ„
β”β”€β”€ clients/
β”‚   β”β”€β”€ base.py                # μ¶”μƒ μΈν„°νμ΄μ¤ (STTClient, LLMClient, TTSClient)
β”‚   β”β”€β”€ whisper_client.py      # π”΄ A6000 λ€μ²΄ λ€μƒ
β”‚   β”β”€β”€ gemini_client.py       # π΅ A6000 λ€μ²΄ λ€μƒ
β”‚   β””β”€β”€ melo_tts_client.py     # π”΄ A6000 λ€μ²΄ λ€μƒ
β”β”€β”€ services/
β”‚   β”β”€β”€ orchestrator.py        # ν•µμ‹¬ λ΅μ§ (STTβ†’LLMβ†’TTS νμ΄ν”„λΌμΈ)
β”‚   β”β”€β”€ audio_processor.py     # ffmpeg λ³€ν™ (webm β†’ wav)
β”‚   β””β”€β”€ question_generator.py  # LLM ν”„λ΅¬ν”„νΈ ν…ν”λ¦Ώ
β”β”€β”€ routers/
β”‚   β””β”€β”€ voice_sessions.py      # /api/session/*, /api/answer/*
β”β”€β”€ scripts/
β”‚   β””β”€β”€ melo_tts_cpu_infer.py  # λ΅μ»¬ MeloTTS λ‹¨μΌ μ¶”λ΅  μ¤ν¬λ¦½νΈ
β””β”€β”€ utils/
    β””β”€β”€ audio_utils.py
```

---

## Client μΈν„°νμ΄μ¤ μ„¤κ³„

### μ¶”μƒ μΈν„°νμ΄μ¤ (`clients/base.py`)

```python
from abc import ABC, abstractmethod

class STTClient(ABC):
    """μμ„± β†’ ν…μ¤νΈ λ³€ν™ ν΄λΌμ΄μ–ΈνΈ"""
    @abstractmethod
    async def transcribe(self, audio_path: str, language: str = "ko") -> str:
        """
        Args:
            audio_path: .wav νμΌ κ²½λ΅
            language: μ–Έμ–΄ μ½”λ“ (ko, en)
        Returns:
            ν…μ¤νΈ λ³€ν™ κ²°κ³Ό
        """
        pass

class LLMClient(ABC):
    """λ€ν• μ–Έμ–΄ λ¨λΈ ν΄λΌμ΄μ–ΈνΈ"""
    @abstractmethod
    async def generate(self, prompt: str, max_tokens: int = 200) -> str:
        """
        Args:
            prompt: μƒμ„± ν”„λ΅¬ν”„νΈ
            max_tokens: μµλ€ ν† ν° μ
        Returns:
            μƒμ„±λ ν…μ¤νΈ
        """
        pass

class TTSClient(ABC):
    """ν…μ¤νΈ β†’ μμ„± λ³€ν™ ν΄λΌμ΄μ–ΈνΈ"""
    @abstractmethod
    async def synthesize(
        self,
        text: str,
        speaker: str = "KR",
        speed: float = 1.0
    ) -> str:
        """
        Args:
            text: μμ„±μΌλ΅ λ³€ν™ν•  ν…μ¤νΈ
            speaker: ν™”μ ID
            speed: μ†λ„ λ°°μ¨
        Returns:
            μƒμ„±λ μμ„± νμΌ URL
        """
        pass
```

---

## κµ¬ν„μ²΄ μμ‹

### WhisperClient (π”΄ A6000 λ€μ²΄ λ€μƒ)

```python
# clients/whisper_client.py
import asyncio
import aiohttp
import os
from clients.base import STTClient


class WhisperLocalClient(STTClient):
    """openai-whisper λ΅μ»¬ λ¨λΈ (CPU/GPU)"""

    def __init__(self, model_size: str = "base", device: str = "cpu"):
        import whisper
        self.model_size = os.getenv("WHISPER_LOCAL_MODEL", model_size)
        self.device = os.getenv("WHISPER_LOCAL_DEVICE", device)
        self._model = whisper.load_model(self.model_size, device=self.device)
        self._use_fp16 = self.device != "cpu"

    async def transcribe(self, audio_path: str, language: str = "ko") -> str:
        loop = asyncio.get_running_loop()
        return await loop.run_in_executor(
            None,
            lambda: self._model.transcribe(
                audio_path,
                language=language,
                fp16=self._use_fp16
            )["text"].strip()
        )


class WhisperA6000Client(STTClient):
    """A6000 μ„λ²„μ Whisper Large-v3 HTTP ν΄λΌμ΄μ–ΈνΈ"""

    def __init__(self, base_url: str):
        self.base_url = base_url

    async def transcribe(self, audio_path: str, language: str = "ko") -> str:
        async with aiohttp.ClientSession() as session:
            with open(audio_path, "rb") as f:
                form = aiohttp.FormData()
                form.add_field("file", f, filename="audio.wav")
                form.add_field("language", language)

                async with session.post(
                    f"{self.base_url}/stt",
                    data=form
                ) as resp:
                    result = await resp.json()
                    return result["text"]
```

### MeloTTSClient (π”΄ A6000 λ€μ²΄ λ€μƒ)

```python
# clients/melo_tts_client.py
import aiohttp
from clients.base import TTSClient

class MeloTTSLocalClient(TTSClient):
    """
    λ΅μ»¬ CPU Melo TTS ν΄λΌμ΄μ–ΈνΈ

    β οΈ A6000 λ§μ΄κ·Έλ μ΄μ… μ‹ MeloTTSA6000Clientλ΅ κµμ²΄
    """
    def __init__(self, base_url: str = "http://localhost:8001"):
        self.base_url = base_url

    async def synthesize(
        self,
        text: str,
        speaker: str = "KR",
        speed: float = 1.0
    ) -> str:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                f"{self.base_url}/tts",
                json={"text": text, "speaker": speaker, "speed": speed}
            ) as resp:
                result = await resp.json()
                return result["audio_url"]


class MeloTTSA6000Client(TTSClient):
    """
    A6000 μ„λ²„μ GPU Melo TTS ν΄λΌμ΄μ–ΈνΈ

    β… μµμΆ… λ°°ν¬μ©
    """
    def __init__(self, base_url: str):
        self.base_url = base_url  # http://a6000-server:8004

    async def synthesize(
        self,
        text: str,
        speaker: str = "KR",
        speed: float = 1.0
    ) -> str:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                f"{self.base_url}/tts",
                json={"text": text, "speaker": speaker, "speed": speed}
            ) as resp:
                result = await resp.json()
                return result["audio_url"]
```

---

## ν™κ²½ λ³€μ κ΄€λ¦¬

```env
# .env

# β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€
# π”΄ Phase 1: MVP (λ΅μ»¬ Whisper)
# β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€
WHISPER_LOCAL_MODEL=base
WHISPER_LOCAL_DEVICE=cpu
GEMINI_API_KEY=AIza...
MELO_TTS_BASE_URL=http://localhost:8001

# β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€
# β… Phase 2: A6000 μ„λ²„
# β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€
USE_A6000_MODELS=false           # trueλ΅ λ³€κ²½ μ‹ A6000 ν΄λΌμ΄μ–ΈνΈ μ‚¬μ©
A6000_STT_URL=http://a6000-server:8002
A6000_LLM_URL=http://a6000-server:8003
A6000_TTS_URL=http://a6000-server:8004
```

### Client ν©ν† λ¦¬ (μλ™ μ „ν™)

```python
# clients/__init__.py
import os
from clients.whisper_client import WhisperLocalClient, WhisperA6000Client
from clients.melo_tts_client import MeloTTSLocalClient, MeloTTSA6000Client


def get_stt_client():
    """ν™κ²½ λ³€μμ— λ”°λΌ STT ν΄λΌμ΄μ–ΈνΈ λ°ν™"""
    if os.getenv("USE_A6000_MODELS") == "true":
        return WhisperA6000Client(os.getenv("A6000_STT_URL"))
    else:
        return WhisperLocalClient()


def get_tts_client():
    """ν™κ²½ λ³€μμ— λ”°λΌ TTS ν΄λΌμ΄μ–ΈνΈ λ°ν™"""
    if os.getenv("USE_A6000_MODELS") == "true":
        return MeloTTSA6000Client(os.getenv("A6000_TTS_URL"))
    else:
        return MeloTTSLocalClient(os.getenv("MELO_TTS_BASE_URL"))
```

---

## λ΅μ»¬ MeloTTS (CPU) μ‚¬μ©λ²•

1. `backend/third_party` μ•„λμ— MeloTTSλ¥Ό ν΄λ΅ ν•λ‹¤.
   ```bash
   cd backend
   mkdir -p third_party
   cd third_party
   git clone https://github.com/myshell-ai/MeloTTS.git
   ```
2. MeloTTS μμ΅΄μ„±μ„ μ„¤μΉν•λ‹¤. (backend μ „μ—­ venv μ¬μ‚¬μ© κ°€λ¥)
   ```bash
   cd backend/third_party/MeloTTS
   pip install -r requirements.txt
   pip install -e .
   # macOSμ—μ„ μ—λ¬κ°€ λ‚λ©΄ pytorch CPU λΉλ“λ¥Ό μλ™ μ„¤μΉ
   ```
3. ν•κµ­μ–΄ ν™”μκ°€ ν•„μ”ν• κ²½μ° λ¨λΈ μ²΄ν¬ν¬μΈνΈλ¥Ό λ‹¤μ΄λ΅λ“ν•κ³ 
   `MeloTTS/checkpoints` ν΄λ”μ— λ°°μΉν•λ‹¤. κΈ°λ³Έ λ¨λΈμ€ μµμ΄ μ¶”λ΅  μ‹ μλ™
   λ‹¤μ΄λ΅λ“ λλ‹¤.
4. λ‹¨μΌ μ¶”λ΅  ν…μ¤νΈλ” μ κ³µλ μ¤ν¬λ¦½νΈλ¥Ό μ‚¬μ©ν•λ‹¤.
    ```bash
    cd backend
    python scripts/melo_tts_cpu_infer.py \
      "μ•λ…•ν•μ„Έμ”! μ¤λ λ©΄μ ‘ μ¤€λΉ„ μ λμ…¨λ‚μ”?" \
      --language KR --speaker KR --speed 1.05 \
      --output tmp/melo_test.wav
    ```
   - `backend/third_party/MeloTTS/melo/pretrained/`μ— `G_0.pth` λ“±μ„
     λ‹¤μ΄λ΅λ“ν•΄λ‘λ©΄ μ¤ν¬λ¦½νΈκ°€ μλ™μΌλ΅ ν•΄λ‹Ή κ²½λ΅λ¥Ό μ‚¬μ©ν•λ‹¤. λ‹¤λ¥Έ μ„μΉμ—
     μ €μ¥ν–λ‹¤λ©΄ `--ckpt-path` λλ” `MELO_TTS_CKPT_PATH` ν™κ²½ λ³€μλ¥Ό μ§€μ •ν•λ‹¤.
5. HTTP μ„λ²„λ¥Ό λ„μ°λ ¤λ©΄ MeloTTS λ ν¬ λ‚΄ `python melo/app.py --device cpu`
   λλ” `python melo/server.py --device cpu --host 0.0.0.0 --port 8001`λ¥Ό μ‹¤ν–‰ν•
   ν›„, λ°±μ—”λ“ `.env`μ—μ„ `MELO_TTS_BASE_URL`μ„ ν•΄λ‹Ή μ£Όμ†λ΅ μ§€μ •ν•λ‹¤.

---

## API μ—”λ“ν¬μΈνΈ

### POST /api/session/start

**μ”μ²­**
```json
{
  "user_id": "u_123",
  "mode": "voice"
}
```

**μ‘λ‹µ**
```json
{
  "session_id": "s_456",
  "question": {
    "id": "q_main_1",
    "text": "μκΈ°μ†κ°λ¥Ό 30μ΄ λ‚΄λ΅ ν•΄μ£Όμ„Έμ”.",
    "audio_url": "http://localhost:8000/static/audio/q_main_1.wav",
    "type": "main"
  }
}
```

### POST /api/answer/complete

**μ”μ²­** (multipart/form-data)
- `session_id`: s_456
- `question_id`: q_main_1
- `turn_type`: "main" | "followup"
- `audio_file`: (webm or wav)

**μ‘λ‹µ**
```json
{
  "answer_text": "μ €λ” λ°±μ—”λ“ κ°λ°μλ΅...",
  "metrics": {
    "duration_sec": 18.2,
    "wpm": 180,
    "filler_count": 3
  },
  "next_question": {
    "id": "q_follow_1",
    "text": "λ°©κΈ λ§μ”€ν•μ‹  ν”„λ΅μ νΈμ—μ„ κ°€μ¥ μ–΄λ ¤μ› λ μ μ€?",
    "audio_url": "http://localhost:8000/static/audio/q_follow_1.wav",
    "type": "followup"
  }
}
```

---

## μ²λ¦¬ νλ¦„

```
1. ν”„λ΅ νΈ: μμ„± λ…Ήμ (webm) β†’ λ°±μ—”λ“ μ—…λ΅λ“
2. λ°±μ—”λ“:
   β”β”€ audio_processor: webm β†’ wav λ³€ν™
   β”β”€ WhisperClient: wav β†’ ν…μ¤νΈ (STT)
   β”β”€ DB μ €μ¥: InterviewVideo, InterviewTranscript
   β”β”€ QuestionGenerator: μ»¨ν…μ¤νΈ + ν”„λ΅¬ν”„νΈ μƒμ„±
   β”β”€ GeminiClient: ν”„λ΅¬ν”„νΈ β†’ κΌ¬λ¦¬μ§λ¬Έ ν…μ¤νΈ (LLM)
   β”β”€ MeloTTSClient: ν…μ¤νΈ β†’ μμ„± URL (TTS)
   β””β”€ μ‘λ‹µ: {answer_text, next_question}
3. ν”„λ΅ νΈ:
   β”β”€ answer_text ν™”λ©΄ ν‘μ‹
   β””β”€ next_question.audio_url μ¬μƒ
```

---

## μ„±λ¥ κ³ λ ¤μ‚¬ν•­

### ν„μ¬ (MVP)
- **STT μ§€μ—°**: ~2-5μ΄ (Whisper API, λ„¤νΈμ›ν¬ μ™•λ³µ)
- **LLM μ§€μ—°**: ~1-3μ΄ (Gemini API)
- **TTS μ§€μ—°**: ~3-8μ΄ (Melo TTS CPU)
- **μ΄ μ§€μ—°**: ~6-16μ΄

### A6000 μ΄ν›„
- **STT μ§€μ—°**: ~0.5-1μ΄ (λ΅μ»¬ GPU)
- **LLM μ§€μ—°**: ~0.3-0.8μ΄ (λ΅μ»¬ GPU)
- **TTS μ§€μ—°**: ~0.5-1μ΄ (λ΅μ»¬ GPU)
- **μ΄ μ§€μ—°**: ~1.3-2.8μ΄ π€

---

## λ΅μ»¬ Melo TTS μ„λ²„ μ‹¤ν–‰

```bash
# backend/scripts/run_melo_tts_server.py
cd backend
CUDA_VISIBLE_DEVICES="" python scripts/run_melo_tts_server.py
```

μ„λ²„λ” `http://localhost:8001`μ—μ„ μ‹¤ν–‰λ¨.

---

## ν…μ¤νΈ μ‹λ‚λ¦¬μ¤

1. **λ‹¨μ„ ν…μ¤νΈ**: κ° Client μΈν„°νμ΄μ¤
2. **ν†µν•© ν…μ¤νΈ**: Orchestrator νμ΄ν”„λΌμΈ
3. **E2E ν…μ¤νΈ**: ν”„λ΅ νΈ β†’ λ°±μ—”λ“ β†’ DB μ €μ¥
4. **μ„±λ¥ ν…μ¤νΈ**: λ™μ‹ μ ‘μ† 10λ…, μ§€μ—° μ‹κ°„ μΈ΅μ •

---

## μ°Έκ³  λ¬Έμ„

- [Melo TTS GitHub](https://github.com/myshell-ai/MeloTTS)
- [OpenAI Whisper API](https://platform.openai.com/docs/guides/speech-to-text)
- [Google Gemini API](https://ai.google.dev/docs)
