"""
Video Analysis Router
ë©´ì ‘ ì˜ìƒ ë¶„ì„ ë° í”¼ë“œë°± ì œê³µ
"""
from fastapi import APIRouter, HTTPException, UploadFile, File, Depends, Form
from sqlalchemy.orm import Session
from pathlib import Path
import soundfile as sf
import os
import json
import shutil
from datetime import datetime
from typing import Optional

from database import get_db
from models import InterviewVideo, InterviewTranscript, NonverbalMetrics, NonverbalTimeline, Feedback, InterviewSession, InterviewQuestion
from pipeline.video_io import extract_frames_opencv, extract_audio_ffmpeg
from pipeline.vision_mediapipe import build_timeline_from_frames, save_timeline
from pipeline.metrics import (
    center_gaze_ratio, smile_ratio, nod_count, emotion_distribution, get_primary_emotion
)
from pipeline.audio_analysis import transcribe_whisper, compute_wpm, compute_filler_count
from pipeline.feedback_generator import generate_feedback_with_gemini, generate_feedback_fallback
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

router = APIRouter()

# ë¹„ë””ì˜¤ ì €ì¥ ë””ë ‰í† ë¦¬
VIDEO_UPLOAD_DIR = Path("uploads/videos")
VIDEO_UPLOAD_DIR.mkdir(parents=True, exist_ok=True)

# Gemini API ì‚¬ìš© ì—¬ë¶€ í™•ì¸ (.env ë¡œë“œ í›„)
USE_GEMINI = bool(os.getenv("GEMINI_API_KEY"))


def generate_feedback(m: dict):
    """ë¶„ì„ ë©”íŠ¸ë¦­ì„ ê¸°ë°˜ìœ¼ë¡œ í•œêµ­ì–´ í”¼ë“œë°± ìƒì„±"""
    fb = []

    # ---- gaze ----
    if m["center_gaze_ratio"] >= 0.8:
        fb.append(f"ì¹´ë©”ë¼ ì‘ì‹œ ë¹„ìœ¨ì´ {m['center_gaze_ratio']:.0%}ë¡œ ë§¤ìš° ì•ˆì •ì ì´ë‹¤. ì •ë©´ ì‹œì„  ìœ ì§€ê°€ ì˜ ëœë‹¤.")
    elif m["center_gaze_ratio"] >= 0.5:
        fb.append(f"ì¹´ë©”ë¼ ì‘ì‹œ ë¹„ìœ¨ì´ {m['center_gaze_ratio']:.0%}ë¡œ ëŒ€ì²´ë¡œ ì–‘í˜¸í•˜ë‹¤. í•µì‹¬ ë‹µë³€ êµ¬ê°„ì—ì„œ ì¡°ê¸ˆ ë” ìœ ì§€í•˜ë©´ ì¢‹ë‹¤.")
    else:
        fb.append(f"ì¹´ë©”ë¼ ì‘ì‹œ ë¹„ìœ¨ì´ {m['center_gaze_ratio']:.0%}ë¡œ ë‚®ë‹¤. ì •ë©´ ì‹œì„ ì„ ë” ì˜ì‹í•´ë³´ë©´ ì‹ ë¢°ê°ì´ ì˜¬ë¼ê°„ë‹¤.")

    # ---- smile ----
    if m["smile_ratio"] >= 0.3:
        fb.append(f"ë¯¸ì†Œ/ê¸ì • í‘œì • ë¹„ìœ¨ì´ {m['smile_ratio']:.0%}ë¡œ ìì—°ìŠ¤ëŸ½ë‹¤. ì¹œê·¼í•œ ì¸ìƒì„ ì¤€ë‹¤.")
    elif m["smile_ratio"] >= 0.1:
        fb.append(f"ë¯¸ì†Œ ë¹„ìœ¨ì´ {m['smile_ratio']:.0%}ë¡œ ì•½ê°„ ì ì„ ìˆ˜ ìˆë‹¤. ì‹œì‘/ë§ˆë¬´ë¦¬ì—ì„œ ê°€ë³ê²Œ ì›ƒì–´ë³´ë©´ ì¢‹ë‹¤.")
    else:
        fb.append(f"ë¯¸ì†Œ ë¹„ìœ¨ì´ {m['smile_ratio']:.0%}ë¡œ ë‚®ë‹¤. í‘œì •ì´ ë”±ë”±í•˜ê²Œ ë³´ì¼ ìˆ˜ ìˆì–´ ì˜ë„ì ìœ¼ë¡œ ë¶€ë“œëŸ¬ìš´ í‘œì •ì„ ë„£ì–´ë³´ì.")

    # ---- nod ----
    if m["nod_count"] == 0:
        fb.append("ê³ ê°œ ë„ë•ì„ì´ ê±°ì˜ ê°ì§€ë˜ì§€ ì•ŠëŠ”ë‹¤. ê³µê°/ë¦¬ìŠ¤ë‹ ì œìŠ¤ì²˜ê°€ ì•½í•´ ë³´ì¼ ìˆ˜ ìˆë‹¤.")
    elif m["nod_count"] <= 2:
        fb.append("ë„ë•ì„ì´ ê³¼í•˜ì§€ ì•Šê³  ì ì ˆí•˜ë‹¤. ê²½ì²­í•˜ëŠ” ì¸ìƒì„ ì¤€ë‹¤.")
    else:
        fb.append("ë„ë•ì„ì´ ë§ì€ í¸ì´ë‹¤. ê³¼ë„í•˜ë©´ ë¶ˆì•ˆí•´ ë³´ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ ì†ë„ë¥¼ ì¡°ê¸ˆ ì¤„ì—¬ë„ ì¢‹ë‹¤.")
    
    # ---- emotion ----
    emotion_dist = m.get("emotion_distribution", {})
    primary_emotion = m.get("primary_emotion")
    
    if emotion_dist and primary_emotion:
        emotion_names = {
            "happy": "ë°ê³  ê¸ì •ì ",
            "pleasant": "ì°¨ë¶„í•˜ê³  í˜¸ê°ê°€ëŠ”",
            "neutral": "ì¤‘ë¦½ì ",
            "surprised": "ë†€ëŒ/ì§‘ì¤‘",
            "concerned": "ê±±ì •ìŠ¤ëŸ¬ìš´"
        }
        emotion_kr = emotion_names.get(primary_emotion, primary_emotion)
        primary_ratio = emotion_dist.get(primary_emotion, 0)
        
        if primary_emotion == "happy" and primary_ratio > 0.4:
            fb.append(f"ì „ì²´ì ìœ¼ë¡œ {emotion_kr} í‘œì •({primary_ratio:.0%})ì´ ìš°ì„¸í•˜ë‹¤. ë§¤ìš° ê¸ì •ì ì¸ ì¸ìƒì„ ì¤€ë‹¤.")
        elif primary_emotion == "pleasant":
            fb.append(f"{emotion_kr} í‘œì •({primary_ratio:.0%})ì´ ì£¼ë¥¼ ì´ë£¬ë‹¤. ì•ˆì •ì ì´ê³  ì‹ ë¢°ê° ìˆëŠ” ì¸ìƒì´ë‹¤.")
        elif primary_emotion == "neutral" and primary_ratio > 0.7:
            fb.append(f"ì¤‘ë¦½ì  í‘œì •({primary_ratio:.0%})ì´ ë§ë‹¤. í•µì‹¬ ë‚´ìš©ì„ ë§í•  ë•Œ ë¯¸ì†Œë¥¼ ë”í•˜ë©´ ì¢‹ë‹¤.")
        elif primary_emotion == "concerned":
            fb.append(f"ë‹¤ì†Œ ê¸´ì¥ëœ í‘œì •({primary_ratio:.0%})ì´ ë³´ì¸ë‹¤. ì‹¬í˜¸í¡í•˜ê³  ì–´ê¹¨ë¥¼ ë‚´ë¦¬ë©´ ì¢‹ë‹¤.")

    # ---- speech ----
    if m["wpm"] > 190:
        fb.append(f"ë§ ì†ë„ê°€ WPM {m['wpm']:.0f}ë¡œ ë¹ ë¥¸ í¸ì´ë‹¤. ë¬¸ì¥ ì‚¬ì´ì— ì§§ì€ í˜¸í¡ì„ ë„£ì–´ ì „ë‹¬ë ¥ì„ ë†’ì—¬ë¼.")
    elif m["wpm"] < 100:
        fb.append(f"ë§ ì†ë„ê°€ WPM {m['wpm']:.0f}ë¡œ ëŠë¦° í¸ì´ë‹¤. í•µì‹¬ ë¬¸ì¥ì€ ì¡°ê¸ˆ ë” ìì‹  ìˆê²Œ ì†ë„ë¥¼ ì¤˜ë„ ì¢‹ë‹¤.")
    else:
        fb.append(f"ë§ ì†ë„(WPM {m['wpm']:.0f})ê°€ ì•ˆì •ì ì´ë‹¤. ë“£ê¸° í¸í•œ í…œí¬ë‹¤.")

    if m["filler_count"] > 6:
        fb.append(f"í•„ëŸ¬(ìŒ/ì–´/uh ë“±)ê°€ {m['filler_count']}íšŒë¡œ ì¦ë‹¤. ë‹µë³€ ì „ 1ì´ˆë§Œ ìƒê°í•˜ê³  ë§í•˜ë©´ í›¨ì”¬ ì¤„ì–´ë“ ë‹¤.")
    else:
        fb.append(f"í•„ëŸ¬ ì‚¬ìš©({m['filler_count']}íšŒ)ì´ ê³¼ë„í•˜ì§€ ì•Šë‹¤. ì „ë°˜ì ìœ¼ë¡œ ìœ ì°½í•˜ë‹¤.")

    return fb


@router.get("/status")
def video_status():
    """API ìƒíƒœ í™•ì¸"""
    return {
        "gemini_api_enabled": USE_GEMINI,
        "feedback_mode": "AI-powered (Gemini 2.5 Flash Lite)" if USE_GEMINI else "Rule-based",
        "upload_directory": str(VIDEO_UPLOAD_DIR.resolve())
    }


@router.post("/upload")
async def upload_video(
    file: UploadFile = File(...),
    user_id: str = Form(...),
    session_id: str = Form(...),
    question_id: str = Form(...),
    db: Session = Depends(get_db)
):
    """
    ë¹„ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ ë° DB ì €ì¥
    
    Args:
        file: ì—…ë¡œë“œí•  ë¹„ë””ì˜¤ íŒŒì¼ (.mp4, .webm, .mov)
        user_id: ì‚¬ìš©ì ID
        session_id: ë©´ì ‘ ì„¸ì…˜ ID
        question_id: ë©´ì ‘ ì§ˆë¬¸ ID
    
    Returns:
        video_id, file_path ë“±
    """
    # íŒŒì¼ í™•ì¥ì ê²€ì¦
    allowed_extensions = {".mp4", ".webm", ".mov", ".avi"}
    file_ext = Path(file.filename).suffix.lower()
    
    if file_ext not in allowed_extensions:
        raise HTTPException(
            status_code=400,
            detail=f"Unsupported file format: {file_ext}. Allowed: {allowed_extensions}"
        )
    
    try:
        # FK ê²€ì¦: session_idì™€ question_idê°€ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        session = db.query(InterviewSession).filter(InterviewSession.id == session_id).first()
        if not session:
            raise HTTPException(
                status_code=404,
                detail=f"InterviewSession not found: {session_id}. Please create a session first."
            )
        
        question = db.query(InterviewQuestion).filter(InterviewQuestion.id == question_id).first()
        if not question:
            raise HTTPException(
                status_code=404,
                detail=f"InterviewQuestion not found: {question_id}. Please create a question first."
            )
        
        # session_idê°€ í•´ë‹¹ user_idì— ì†í•˜ëŠ”ì§€ í™•ì¸
        if session.user_id != user_id:
            raise HTTPException(
                status_code=403,
                detail=f"Session {session_id} does not belong to user {user_id}"
            )
        
        # ê³ ìœ  íŒŒì¼ëª… ìƒì„±
        timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
        unique_filename = f"{user_id}_{session_id}_{timestamp}{file_ext}"
        video_path = VIDEO_UPLOAD_DIR / unique_filename
        
        # íŒŒì¼ ì €ì¥
        with open(video_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        
        # ë¹„ë””ì˜¤ ê¸¸ì´ ì¶”ì¶œ
        import cv2
        cap = cv2.VideoCapture(str(video_path))
        fps = cap.get(cv2.CAP_PROP_FPS)
        frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)
        duration_sec = frame_count / fps if fps > 0 else 0
        cap.release()
        
        # DBì— ì €ì¥
        video_record = InterviewVideo(
            user_id=user_id,
            session_id=session_id,
            question_id=question_id,
            video_url=str(video_path),
            duration_sec=float(duration_sec)
        )
        db.add(video_record)
        db.commit()
        db.refresh(video_record)
        
        return {
            "video_id": video_record.id,
            "filename": unique_filename,
            "file_path": str(video_path),
            "duration_sec": duration_sec,
            "created_at": video_record.created_at
        }
        
    except HTTPException:
        # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì „ë‹¬
        raise
    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒì‹œ ì—…ë¡œë“œëœ íŒŒì¼ ì‚­ì œ
        if 'video_path' in locals() and video_path.exists():
            video_path.unlink()
        raise HTTPException(status_code=500, detail=f"Upload failed: {str(e)}")


@router.post("/analyze/{video_id}")
def analyze_interview(video_id: str, db: Session = Depends(get_db)):
    """
    ì—…ë¡œë“œëœ ë¹„ë””ì˜¤ ë¶„ì„ ë° AI í”¼ë“œë°± ìƒì„± + DB ì €ì¥
    
    Args:
        video_id: InterviewVideo ID
    
    Environment Variables:
        - GEMINI_API_KEY: Gemini API í‚¤ (ì„¤ì •ì‹œ AI í”¼ë“œë°± ì‚¬ìš©)
    
    Returns:
        - ë¶„ì„ ê²°ê³¼ + DBì— ì €ì¥ëœ ë ˆì½”ë“œ IDs
    """
    # 1. DBì—ì„œ ë¹„ë””ì˜¤ ì •ë³´ ì¡°íšŒ
    video_record = db.query(InterviewVideo).filter(InterviewVideo.id == video_id).first()
    if not video_record:
        raise HTTPException(status_code=404, detail=f"Video not found: {video_id}")
    
    video_path = Path(video_record.video_url)
    if not video_path.exists():
        raise HTTPException(
            status_code=404,
            detail=f"Video file not found: {video_path}"
        )
    
    try:
        # 2. ë¹„ë””ì˜¤ ë¶„í•´
        print(f"ğŸ¬ Processing video: {video_path}")
        
        artifacts_dir = Path("artifacts") / video_id
        frames_dir = artifacts_dir / "frames"
        
        frames = extract_frames_opencv(
            video_path, fps=5.0, out_dir=frames_dir
        )

        # 3. Vision timeline ìƒì„±
        print("ğŸ‘ï¸ Analyzing facial features...")
        timeline = build_timeline_from_frames(frames)
        timeline_path = artifacts_dir / "timeline.json"
        save_timeline(timeline, timeline_path)

        # 4. ì˜¤ë””ì˜¤ ë¶„ì„
        print("ğŸ¤ Analyzing audio...")
        wav_path = artifacts_dir / "audio.wav"
        wav = extract_audio_ffmpeg(video_path, wav_path)
        audio, sr = sf.read(str(wav))
        duration_sec = len(audio) / sr
        
        print("ğŸ“ Transcribing speech...")
        stt = transcribe_whisper(wav, model_size="base")
        text = stt["text"]

        # 5. ë©”íŠ¸ë¦­ ê³„ì‚°
        print("ğŸ“Š Computing metrics...")
        emotion_dist = emotion_distribution(timeline)
        primary_emo = get_primary_emotion(timeline)
        
        metrics = {
            "center_gaze_ratio": center_gaze_ratio(timeline),
            "smile_ratio": smile_ratio(timeline, threshold=None),
            "nod_count": nod_count(timeline),
            "emotion_distribution": emotion_dist,
            "primary_emotion": primary_emo,
            "wpm": compute_wpm(text, duration_sec),
            "filler_count": compute_filler_count(text),
        }

        # 6. í”¼ë“œë°± ìƒì„±
        if USE_GEMINI:
            print("ğŸ¤– Generating feedback with Gemini 2.5 Flash Lite...")
            try:
                feedback_list = generate_feedback_with_gemini(metrics, transcript=text)
                feedback_mode = "gemini"
            except Exception as e:
                print(f"âš ï¸ Gemini failed, using fallback: {e}")
                feedback_list = generate_feedback_fallback(metrics)
                feedback_mode = "rule-based"
        else:
            print("ğŸ“ Generating feedback with rule-based system...")
            feedback_list = generate_feedback_fallback(metrics)
            feedback_mode = "rule-based"

        # 7. DBì— ì €ì¥
        print("ğŸ’¾ Saving to database...")
        
        # 7-1. Transcript ì €ì¥
        transcript_record = InterviewTranscript(
            video_id=video_id,
            text=text,
            language="ko"  # Whisperê°€ ìë™ ê°ì§€í•˜ì§€ë§Œ ê¸°ë³¸ê°’
        )
        db.add(transcript_record)
        
        # 7-2. NonverbalMetrics ì €ì¥
        metrics_record = NonverbalMetrics(
            video_id=video_id,
            center_gaze_ratio=metrics["center_gaze_ratio"],
            smile_ratio=metrics["smile_ratio"],
            nod_count=metrics["nod_count"],
            wpm=metrics["wpm"],
            filler_count=metrics["filler_count"],
            primary_emotion=primary_emo
        )
        db.add(metrics_record)
        
        # 7-3. NonverbalTimeline ì €ì¥
        timeline_record = NonverbalTimeline(
            video_id=video_id,
            timeline_json=json.dumps(timeline, ensure_ascii=False)
        )
        db.add(timeline_record)
        
        # 7-4. Feedback ì €ì¥
        feedback_records = []
        for idx, feedback_text in enumerate(feedback_list):
            # í”¼ë“œë°± ë¶„ë¥˜ (ê°„ë‹¨í•œ ê·œì¹™)
            if any(word in feedback_text for word in ["ìš°ìˆ˜", "ì•ˆì •ì ", "ìì—°ìŠ¤ëŸ½", "ì ì ˆ", "ê¸ì •ì "]):
                severity = "info"
                title = "ê°•ì "
            elif any(word in feedback_text for word in ["ê³¼ë‹¤", "ë§", "ë”±ë”±", "ë‚®", "ê¸´ì¥"]):
                severity = "warning"
                title = "ê°œì„  í•„ìš”"
            else:
                severity = "suggestion"
                title = "ì œì•ˆ"
            
            feedback_rec = Feedback(
                video_id=video_id,
                level="video",
                title=f"{title} #{idx+1}",
                message=feedback_text,
                severity=severity
            )
            feedback_records.append(feedback_rec)
            db.add(feedback_rec)
        
        # ì»¤ë°‹
        db.commit()
        
        print("âœ… Analysis complete!")
        
        return {
            "video_id": video_id,
            "metrics": metrics,
            "feedback": feedback_list,
            "feedback_mode": feedback_mode,
            "transcript": text,
            "database_records": {
                "transcript_id": transcript_record.id,
                "metrics_id": metrics_record.id,
                "timeline_id": timeline_record.id,
                "feedback_ids": [f.id for f in feedback_records]
            }
        }
    
    except Exception as e:
        db.rollback()
        raise HTTPException(
            status_code=500,
            detail=f"Video analysis failed: {str(e)}"
        )


@router.get("/results/{video_id}")
def get_analysis_results(video_id: str, db: Session = Depends(get_db)):
    """
    ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
    
    Args:
        video_id: InterviewVideo ID
    
    Returns:
        ë¹„ë””ì˜¤, ë©”íŠ¸ë¦­, í”¼ë“œë°±, ì „ì‚¬ ë“± ëª¨ë“  ë¶„ì„ ê²°ê³¼
    """
    # ë¹„ë””ì˜¤ ì •ë³´
    video = db.query(InterviewVideo).filter(InterviewVideo.id == video_id).first()
    if not video:
        raise HTTPException(status_code=404, detail=f"Video not found: {video_id}")
    
    # ë©”íŠ¸ë¦­ (ê°€ì¥ ìµœì‹  ê²ƒ ì¡°íšŒ)
    metrics = db.query(NonverbalMetrics).filter(
        NonverbalMetrics.video_id == video_id
    ).order_by(NonverbalMetrics.created_at.desc()).first()
    
    # í”¼ë“œë°±
    feedbacks = db.query(Feedback).filter(Feedback.video_id == video_id).all()
    
    # ì „ì‚¬
    transcript = db.query(InterviewTranscript).filter(InterviewTranscript.video_id == video_id).first()
    
    # íƒ€ì„ë¼ì¸ (ê°€ì¥ ìµœì‹  ê²ƒ ì¡°íšŒ)
    timeline = db.query(NonverbalTimeline).filter(
        NonverbalTimeline.video_id == video_id
    ).order_by(NonverbalTimeline.created_at.desc()).first()
    
    # íƒ€ì„ë¼ì¸ì—ì„œ emotion_distribution ê³„ì‚°
    emotion_dist = {}
    primary_emo = None
    if timeline:
        try:
            timeline_data = json.loads(timeline.timeline_json)
            emotion_dist = emotion_distribution(timeline_data)
            primary_emo = get_primary_emotion(timeline_data)
        except Exception as e:
            print(f"âš ï¸ íƒ€ì„ë¼ì¸ íŒŒì‹± ì‹¤íŒ¨: {e}")
    
    # metricsì˜ primary_emotionì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
    if metrics and metrics.primary_emotion:
        primary_emo = metrics.primary_emotion
    
    return {
        "video": {
            "id": video.id,
            "user_id": video.user_id,
            "session_id": video.session_id,
            "question_id": video.question_id,
            "duration_sec": video.duration_sec,
            "created_at": video.created_at
        },
        "metrics": {
            "center_gaze_ratio": metrics.center_gaze_ratio if metrics else None,
            "smile_ratio": metrics.smile_ratio if metrics else None,
            "nod_count": metrics.nod_count if metrics else None,
            "wpm": metrics.wpm if metrics else None,
            "filler_count": metrics.filler_count if metrics else None,
            "primary_emotion": primary_emo,
            "emotion_distribution": emotion_dist,
        } if metrics else None,
        "feedbacks": [
            {
                "id": f.id,
                "title": f.title,
                "message": f.message,
                "severity": f.severity,
                "level": f.level
            } for f in feedbacks
        ],
        "transcript": transcript.text if transcript else None,
        "timeline_available": timeline is not None
    }
